# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434

# Default Model
# Use any model you have installed in Ollama
# Examples: qwen2.5:latest, llama3.1:latest, mistral:latest, codellama:latest
DEFAULT_MODEL=qwen2.5:latest

# Disabled Tools
# Comma-separated list of tools to disable
# Available tools: chat, listmodels, version, debug, thinkdeep, planner, consensus, codereview, precommit
DISABLED_TOOLS=

# Memory Management
# Maximum number of conversations to keep in memory (default: 100)
MAX_CONVERSATIONS=100
